# The Google File System

## Abstract
- The Google File System is a scalable distributed file system 
for large distributed data-intensive applications.
- It provides fault tolerance while running on inexpensive commodity hardware, and it delivers high aggregate performance to a large number of clients.

## 1. INTRODUCTION
- GFS shares many of the same goals as previous distributed file systems such as performance, scalability, reliability, and availability.
- In GFS, component failures are the norm rather than the exception. Constant monitoring, error detection, fault tolerance, and automatic recovery must be intefral to the system.
- Files are huge by traditional standards.
- Most files are mutated by appending new data rather than overwriting existing data. Random writes within a file are practically non-existent. Once written, the files are only read, and often only sequentially.
- Co-designing the applications and the file system API benefits the overall system by increasing our flexibility.

## 2. DESIGN OVERVIEW
### 2.1 Assumptions
- Assumptions in more details:
    - The system is built from many inexpensive commodity components that often fail. It must constantly monitor itself and detect, tolerate, and recover promptly from component failures on a routine basis.
    - The system stores a modest number of large files
    - The workloads primarily consist of two kinds of reads: large streaming reads and small random reads.
    - The workloads also have many large, sequential writes that append data to files.
    - The system must efficiently implement well-defined semantics for multiple clients that concurrently append to the same file.
    - High sustained bandwidth is more important than low latency.

### 2.2 Interface
- GFS provides a familiar file system interface, though it does not implement a standard API such as POSIX. (GFS support the usual operations to *create, delete, open, close, read* and *write* files)
- GFS has *snapshot* and *record append* operations. Snapshot creates a copy of a file or directory tree at low cost. Record append allows multiple clients to append data to the same file concurrently while guaranteeing the atomicity of each individual clientâ€™s append. 

### 2.3 Architecture
- A GFS cluster consists of a single *master* and multiple *chunkservers* and is accessed by multiple *clients*, as shown Figure 1
- File are divided into fixed-size *chunks*. Each chunk identified by an immutable and globally unique 64 bit *chunk handle* assigned by the master at the time of chunk creation.
- Chunkservers store chunks on local disks as Linux files and read or write chunk data specified by a chunk handle and byte range. For reliability, each chunk is replicated on multiple chunkservers.
- The master maintains all file system metadata. This includes the namespace, access control information, the mapping from files to chunks, and the current locations of chunks.
- The master controls system-wide activities such as chunk lease management, garbage collection of orphaned chunks, and chunk migration between chunkservers.
-  The master periodically communicates with each chunkserver in HeartBeat messages to give it instructions and collect its state.
- GFS client code linked into each application implements the file system API and communicates with the master and chunkservers to read or write data on behalf of the application.
- Neither the client nor the chunkserver caches file data.

![alt text](/resource/image/GFS(2003)-figure-1.png)

### Single Master
- Clients never read and write file data through the master. Instead, a client asks the master which chunkservers it should contact. It caches this information for a limited time and interacts with chunkservers directly for many subsequent operations.
- Explain the interactions for a simple read with reference to Figure 1.
  - First, using the fixed chunk size, the client translates the file name and byte offset specified by the application into a chunk index within the file
  - Then, it sends the master a request containing the file name and chunk index.
  - The master replies with corresponding chunk handle and locations of the replicas.
  - The client caches this information using the file name and chunk index as the key
  - The client then sends a request to one of the replicas, most likely the closet one. The request specifies the chunk handle and a byte range within that chunk. Futher reads of the same chunk require no more client-master interaction until the cached information expires or the file is reopened
  
### 2.5 Chunk Size
- Chunk size is one of the key design parameters.
- The chunk size is 64MB. Each chunk replica is stored as a plain Linux file on a chunkserver and is extended only as needed.
- A large chunk size offers several important advantages.
    - It reduces client's need to interact with the master, because reads and writes on the same chunk require only one initial request to the master for chunk location information.
    - It can reduce network overhead by keeping a persistent TCP connection to the chunkserver over an extended period of time.
    - It reduces the size of the metadata stored on the master. (This allows us to keep the metadata in memory)
- Disavantages:
    - A small file consists of a small number of chunks, perhaps jush one. The chunkservers storing those chunks may become hot spots if many clients are accessing the same time

### 2.6 Metadata
- The master stores three major types of metadata:
  - The file and chunk namespaces
  - The mapping from files to chunks
  - The locations of each chunk's replicas
- All metadata is kept in the master's memory.
- Two types (Namespaces and file to chunks mapping) are also kept persistent by logging mutations to an operation log stored on the master's local disk and replicated on remote machines. Using a log allows to update the master state simply, reliably, and without risking inconsistencies in event of a master crash.

#### 2.6.1 In-memory Data Structures
- Since metadata is stored in memory, master operations are fast.
- It is easy and efficent for the master to periodically scan through its entire state in the background. This periodic scanning is used to implement chunk garbage collection, re-replication in the presence of chunkserver failures, and chunk migration to balance load and disk space usage across chunkservers

#### 2.6.2 Chunk Locations
- The master does not keep a persistent record of which chunkservers have a replica of a given chunk.
- It simply polls chunkservers for that information at startup. The master can keep itself up-to-date thereafter because it controls all chunk placement and monitors chunkserver status with regular HeartBeat messages.

#### 2.6.3 Operation Log
- The operation log contains a historical record of critical metadata changes. It is central to GFS
- Not only is it the only persistent record of metadata, but it also serves as a logical time line the defines the order of concurrent operations

### 2.7 Consistency Model
- GFS has a relaxed consistency model that supports our highly distributed applications well but remains relatively simple and efficient to implement

#### 2.7.1 Guarantees by GFS
- File namespace mutations (e.g., file creation) are atomic. They are handled exclusively by the master, ensuring atomicity and correctness.
- The state of a file region after a data mutation depends on the type of mutation, its success or failure, and the presence of concurrent mutations.
- A file region is consistent if all clients see the same data, regardless of which replicas they read from.
- A region is defined if it is consistent and clients see the complete data written by the mutation.
- Successful mutations without interference result in a defined and consistent region.
- Concurrent successful mutations leave the region undefined but consistent, meaning all clients see the same data, but it may be a mix of multiple mutations.
- Failed mutations make the region inconsistent and undefined, leading to different clients seeing different data at different times.

#### 2.7.2 Implications for Applications
- GFS applications can handle the relaxed consistency model with simple techniques like appending rather than overwriting, checkpointing, and writing self-validating records
- Most applications append data to files instead of overwriting them. Writers generate files from beginning to end and rename them atomically after writing all the data or periodically checkpoint the progress.
- Checkpoints may include application-level checksums, allowing reader to verify and process only the defined regions of the file.
- This approach is efficient and resilient to application failures, as appending is more efficient than random writes
- In cases where many writers append to a file concurrently, record append semantics ensure each writer's output is preserved.
- Readers handle occasional padding and duplicates by using checksums and unique identifiers in records to verify validity and filter out duplicates.

## 3. SYSTEM INTERACTIONS
### 3.1 Leases and Mutation Order
- **Mutation**: Operations that change the contents or metadata of a chunk, such as writes or appends.
- **Leases**: The master grants a lease to one of the chunk replicas, called the primary, to maintain a consistent order across replicas.
- **Primary Replica**: The primary replica picks a serial order for all mutations to the chunk, and all replicas follow this order when applying mutations.
- **Lease timeout**: A lease has an initial timeout of 60 seconds but can be extended indefinitely as long as the chunk is being mutated
- **Write Process**:
  1. The client asks the master which chunkserver holds the current lease for the chunk and the locations of other replicas
  2. The master replies with the identity of the primary and the locations of the other replicas.
  3. The client pushes the data to all replicas.
  4. Once all replicas acknowledge receiving the data, the client sends a write request to the primary
  5. The primary assigns serial numbers to mutations and applies them to its local state.
  6. The primary forwards the write request to all secondary replicas.
  7. The secondaries apply mutations in the same serial number order and reply to the primary.
  8. The primary replies to the client, completing the write process

![alt text](/resource/image/GFS(2003)-figure-2.png)

### 3.2 Data Flow
- **Decoupling Control and Data Flow**: GFS separates the flow of data from the flow of control to use the network efficiently. Control flows from the client to the primary and then to all secondaries, while data is pushed linearly along a chain of chunkservers in a pipelined fashion. Avoid network bottlenecks
- **Network Utilization**: Data is pushed linearly to fully utilize each machine's network bandwidth. Each machine forwards the data to the "closet" machine in the network topology that has not received it yet.
- **Minimizing Latency**: Pipelining the data transfer over TCP connections minimizes latency. Once a chunkserver receives some data, it starts forwarding immediately. This approach is especially effective in a switched network with full-duplex links

### 3.3 Atomic Record Appends
- **Record Append Operation**: In a traditional write, the client specifies the offset at which data is to be written. Concurrent writes to the same region are not serializable and may result in data fragments from multiple clients.
- **Atomic Append**: In a record append, the client specifies only the data, and GFS appends it to the file at least once atomically at an offset of GFS's choosing. This ensures that the data is written as one continuous sequence of bytes
- **Concurrent Appends**: Record append is heavily used by distributed applications where many clients append to the same file concurrently. This avoids the need for additional synchronization mechanisms.
- **Control Flow**: The client pushes the data to all replicas of the last chunk of the file, then sends a request to the primary. The primary checks if appending the record would cause the chunk to exceed the maximum size. If so, it pads the chunk to the maximum size and instructs secondaries to do the same, then retries the operation on the next chunk.
- **Handling Failures**: If a record append fails at any replica, the client retries the operation. This may result in replicas containing different data, including duplicates of the same record. GFS guarantees that the data is written at least once as an atomic unit.

### 3.4 Snapshot
- **Snapshot Operation**: The snapshot operation creates a copy of a file or directory tree almost instantaneously, minimizing interruptions to ongoing mutations.
- **Copy-on-Write Technique**: GFS uses standard copy-on-write techniques to implement snapshots. When the master receives a snapshot request, it revokes any outstanding leases on the chunks in the files to be snapshotted.
- **Metadata Duplication**: The master logs the snapshot operation to disk and duplicates the metadata for the source file or directory tree. The newly created snapshot files point to the same chunks as the source files.
- **Chunk Creation**: When a client wants to write to a chunk after the snapshot operation, the master creates a new chunk on the same chunkservers as the original chunk. This ensures that data can be copied locally, not over the network.
- **Lease Management**: The master grants a lease on the new chunk to one of the replicas and replies to the client, allowing the client to write to the chunk normally.

## 4. MASTER OPERATION
### 4.1 Namespace Management and Locking
- **Namespace Operations**: The master executes all namespace operations, such as file creation, deletion, and snapshot.
- **Locking Mechanism**: To ensure proper serialization of concurrent operations, GFS uses a locking mechanism over regions of the namespace. Each node in the namespace tree has an associated read-write lock.
- **Lock Acquisition**: Operations acquire a set of locks before running. For example, creating a file /home/user/foo requires read locks on /home and /home/user, and a write lock on /home/user/foo.
- **Concurrent Mutations**: The locking scheme allows concurrent mutations in the same directory. Multiple file creations can be executed concurrently in the same directory.
- **Deadlock Prevention**: Locks are acquired in a consistent total order to prevent deadlock. They are ordered by level in the namespace tree and lexicographically within the same level.

### 4.2 Replica Placement
- **Distribution Levels**: A GFS cluster is highly distributed across multiple levels, including hundreds of chunkservers spread across many machine racks. These chunkservers may be accessed from hundreds of clients from the same or different racks.
- **Replica Placement Policy**: The policy aims to maximize data reliability and availability, as well as network bandwidth utilization. It is not enough to spread replicas across machines; they must also be spread across racks to ensure availability even if an entire rack fails.
- **Survivability and Bandwidth**: Spreading replicas across racks ensures that some replicas will survive and remain available even if a rack is damaged or offline. This also allows read traffic to exploit the aggregate bandwidth of multiple racks, although write traffic must flow through multiple racks.

### 4.3 Creation, Re-replication, Rebalancing
- **Chunk Creation**: When the master creates a chunk, it places the initial replicas on chunkservers with below-average disk space utilization, limits the number of recent creations on each chunkserver, and spreads replicas across racks to ensure reliability and availability.
- **Re-replication**: The master re-replicates a chunk as soon as the number of available replicas falls below a user-specified goal. This can happen due to chunkserver unavailability, corruption, disk errors, or increased replication goals. The master prioritizes chunks based on how far they are from their replication goal, whether they belong to live files, and if they are blocking client progress.
- **Rebalancing**: The master periodically rebalances replicas to improve disk space and load distribution. It moves replicas to equalize disk space usage and gradually fills up new chunkservers to avoid overwhelming them with new chunks and heavy write traffic.

### 4.4 Garbage Collection
#### 4.4.1 Mechanism
- **File Deletion**: When a file is deleted by the application, the master logs the deletion immediately, just like other changes. However, instead of reclaiming resources immediately, the file is renamed to a hidden name that includes the deletion timestamp.
- **Delayed Reclamation**: During the masterâ€™s regular scan of the file system namespace, it removes any hidden files that have existed for more than three days (the interval is configurable). Until then, the file can still be read under the new, special name and can be undeleted by renaming it back to normal.
- **Metadata Erasure**: When the hidden file is removed from the namespace, its in-memory metadata is erased, effectively severing its links to all its chunks.
- **Orphaned Chunks**: In a similar regular scan of the chunk namespace, the master identifies orphaned chunks (those not reachable from any file) and erases the metadata for those chunks.
- **Chunkserver Reports**: In a HeartBeat message regularly exchanged with the master, each chunkserver reports a subset of the chunks it has, and the master replies with the identity of all chunks that are no longer present in the masterâ€™s metadata. The chunkserver is then free to delete its replicas of such chunks.

#### 4.4.2 Discussion
- **Advantages of Garbage Collection**: The garbage collection approach to storage reclamation offers several advantages over eager deletion. It is simple and reliable in a large-scale distributed system where component failures are common. Garbage collection provides a uniform and dependable way to clean up any replicas not known to be useful.
- **Batch Processing**: Storage reclamation is merged into the regular background activities of the master, such as regular scans of namespaces and handshakes with chunkservers. This is done in batches, and the cost is amortized. It is done only when the master is relatively free, allowing it to respond more promptly to client requests that demand timely attention.
- **Safety Net**: The delay in reclaiming storage provides a safety net against accidental, irreversible deletion.
- **Disadvantages**: The delay in reclaiming storage can hinder efforts to fine-tune usage when storage is tight. Applications that repeatedly create and delete temporary files may not be able to reuse storage immediately. To address this, GFS allows expedited storage reclamation for explicitly deleted files and different reclamation policies for different parts of the namespace.

### 4.5 Stale Replica Detection
- **Stale Replicas**: Chunk replicas may become stale if a chunkserver fails and misses mutations to the chunk while it is down.
- **Chunk Version Numbers**: The master maintains a chunk version number for each chunk to distinguish between up-to-date and stale replicas.
- **Lease Granting**: Whenever the master grants a new lease on a chunk, it increases the chunk version number and informs the up-to-date replicas. This occurs before any client is notified and before any writing can start.
- **Detection of Stale Replicas**: If a chunkserver is unavailable and later restarts, it reports its set of chunks and their associated version numbers to the master. The master detects stale replicas by comparing these version numbers.
- **Garbage Collection**: Stale replicas are removed during the masterâ€™s regular garbage collection. The master effectively considers a stale replica not to exist when replying to client requests for chunk information.
- **Client and Chunkserver Verification**: The master includes the chunk version number when informing clients or chunkservers about chunk locations. Clients and chunkservers verify the version number to ensure they are accessing up-to-date data.

## 5.  FAULT TOLERANCE AND DIAGNOSIS
### 5.1 High Availability
- **Fast Recovery**: Both the master and chunkserver are designed to restore their state and restart in seconds, regardless of how they terminated. This ensures minimal disruption to clients and other servers.
- **Chunk Replication**: Each chunk is replicated on multiple chunkservers across different racks. Users can specify different replication levels for different parts of the file namespace. The default replication level is three. The master clones existing replicas as needed to maintain the desired replication level, even when chunkservers go offline or detect corrupted replicas.
- **Master Replication**: The master state is replicated for reliability. The operation log and checkpoints are replicated on multiple machines. A mutation to the state is considered committed only after its log record has been flushed to disk locally and on all master replicas. Shadow masters provide read-only access to the file system even when the primary master is down, enhancing read availability.

### 5.2 Data Integrity
- **Checksumming**: Each chunkserver uses checksumming to detect data corruption. Chunks are divided into 64KB blocks, each with a corresponding 32-bit checksum. Checksums are kept in memory and stored persistently with logging, separate from user data.
- **Read Verification**: During reads, the chunkserver verifies the checksum of data blocks before returning any data. If a block does not match the recorded checksum, the chunkserver returns an error and reports the mismatch to the master. The master then clones the chunk from another replica and instructs the chunkserver to delete the corrupted replica.
- **Write Optimization**: Checksum computation is optimized for writes that append to the end of a chunk. For overwrites, the chunkserver verifies the first and last blocks of the range being overwritten, performs the write, and then computes and records the new checksums.
- **Idle Period Scanning**: During idle periods, chunkservers scan and verify the contents of inactive chunks to detect corruption in rarely read chunks. The master creates a new uncorrupted replica and deletes the corrupted one.

### 5.3 Diagnostic Tools
- **Diagnostic Logging**: GFS servers generate extensive and detailed diagnostic logs that record significant events and all RPC requests and replies. These logs help in problem isolation, debugging, and performance analysis.
- **RPC Logs**: The RPC logs include the exact requests and responses sent on the wire, except for the file data being read or written. By matching requests with replies and collating RPC records on different machines, the entire interaction history can be reconstructed to diagnose problems.
- **Performance Impact**: The performance impact of logging is minimal because logs are written sequentially and asynchronously. The most recent events are kept in memory and available for continuous online monitoring.